{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Hindi Whisper ASR using OpenAI Whisper Model**\n",
        "\n",
        "using one of the audio file of kathbath dataset (audio hindi) to test the model and find WER"
      ],
      "metadata": {
        "id": "tDh3Ay1tOAhO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6pF_ex-aZ-J",
        "outputId": "585816a1-949b-4a90-9325-bba5ffa169d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyloudnorm in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm) (1.11.4)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm) (1.25.2)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm) (0.18.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyloudnorm\n",
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ2bZsC4Kzoz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "%matplotlib inline\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# import splitfolders\n",
        "import skimage.io\n",
        "import pydub\n",
        "\n",
        "import librosa as lr\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y24AHL5er7U",
        "outputId": "ff6f6245-368e-4934-d67f-3f3482277f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-5knmnl_p\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-5knmnl_p\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.6.0)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.4)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper"
      ],
      "metadata": {
        "id": "9xQQ6kNTeej6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d7s4zCTNJQ4",
        "outputId": "c7ea1a83-de81-4ada-eb82-08ff9f2c9602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_tiny = whisper.load_model(\"tiny\") #Tiny whisper model"
      ],
      "metadata": {
        "id": "iG3J7htpegdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_medium = whisper.load_model(\"medium\") #Medium whisper model"
      ],
      "metadata": {
        "id": "Qzzp01yIQ0a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_large = whisper.load_model(\"large\")"
      ],
      "metadata": {
        "id": "0CbO8vSDb_ex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38d244df-6d64-40a4-fa47-dda25a02a7a7"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:65: UserWarning: /root/.cache/whisper/large-v3.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
            "  warnings.warn(\n",
            "100%|█████████████████████████████████████| 2.88G/2.88G [00:46<00:00, 65.9MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Convert_wav_2_mp3(rootdir):\n",
        "\n",
        "  for it in os.scandir(rootdir):\n",
        "    if it.is_dir():\n",
        "      category_dir = it.path\n",
        "      print(category_dir)\n",
        "\n",
        "      #Read contents in this directory\n",
        "      for file in os.listdir(category_dir):\n",
        "        filename = os.fsencode(file)\n",
        "        filename = filename.decode()\n",
        "        #print(filename)\n",
        "        if filename.endswith(\".wav\"):\n",
        "          # Get an audio file to be processed from the directory\n",
        "           audio_path = (os.path.join(category_dir,filename))\n",
        "           #print(audio_path)\n",
        "\n",
        "           mp3_file = os.path.splitext(filename)[0] + '.mp3' #name the file with .mp3 extension\n",
        "           path_to_save = (os.path.join(category_dir,mp3_file))\n",
        "           #print(path_to_save)\n",
        "\n",
        "           sound = pydub.AudioSegment.from_wav(audio_path) #convert to .mp3\n",
        "           sound.export(path_to_save, format=\"mp3\")"
      ],
      "metadata": {
        "id": "BztOh7uvJsxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "audioPathHindi = '/content/drive/MyDrive/hindi/test/audio/844424930627596-153-f.wav'\n",
        "outputPathMp3 = '/content/drive/MyDrive/hindi/test/audio/audio1-f.mp3'\n",
        "\n",
        "sound = AudioSegment.from_wav(audioPathHindi)\n",
        "\n",
        "sound.export(outputPathMp3, format=\"mp3\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5XFHn86td5l",
        "outputId": "ab3c8b2b-2603-4bf8-d96e-88a88af56eed"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/content/drive/MyDrive/hindi/test/audio/audio1-f.mp3'>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audioHindi = whisper.load_audio(\"/content/drive/MyDrive/hindi/test/audio/audio1-f.mp3\")"
      ],
      "metadata": {
        "id": "gzP4hryqrUyS"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "audioHindi = whisper.pad_or_trim(audioHindi)\n"
      ],
      "metadata": {
        "id": "9HAjCg7lz6iG"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make log-Mel spectrogram and move to the same device as the model\n",
        "mel = whisper.log_mel_spectrogram(audioHindi).to(model_medium.device)\n",
        "\n",
        "# detect the spoken language\n",
        "_, probs = model_medium.detect_language(mel)\n",
        "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
        "\n",
        "# decode the audio\n",
        "options = whisper.DecodingOptions()\n",
        "result = whisper.decode(model_medium, mel, options)\n",
        "\n",
        "# print the recognized text\n",
        "print(result.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjG8hDv4ehca",
        "outputId": "4a3562bf-aa3a-4ff2-d66c-035527d4b1c7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: hi\n",
            "रिया चक्रवर्ती को आज भाई खला जेल में चटाई बिचाकर राद गुजार नहीं पड़ेगी।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Hindi to English\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Cx4UW_-x6UfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jiwer\n",
        "\n",
        "# Ground truth (actual) text and transcribed text\n",
        "actual_text = \"आज रिया चक्रवर्ती को भाई खाला जेल में चटाई पर रहने से मुक्ति मिल जाएगी.\"\n",
        "transcribed_text = result.text\n",
        "\n",
        "# Normalize texts if needed\n",
        "# For Hindi, normalization might not be as crucial, but it's still good practice\n",
        "\n",
        "# Calculate WER\n",
        "wer = jiwer.wer(actual_text, transcribed_text)\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PmCW_4ANAfX",
        "outputId": "f923fbe2-60a5-4e38-bd6c-8bef1bc81b22"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 60.00 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "options = {\"fp16\": False, \"language\": \"hi\", \"task\": \"translate\"}\n",
        "result = model_medium.transcribe(audioHindi, **options)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwHCRdT75cYc",
        "outputId": "8beb3e92-7788-408b-a270-7ee55f2e82b6"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ' Rhea Chakrabarti will have to spend the night in Bhai Khala Jail', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 7.0, 'text': ' Rhea Chakrabarti will have to spend the night in Bhai Khala Jail', 'tokens': [50364, 497, 27799, 761, 514, 5305, 40155, 486, 362, 281, 3496, 264, 1818, 294, 13550, 1301, 11681, 5159, 508, 864, 50714], 'temperature': 0.0, 'avg_logprob': -0.44376407970081677, 'compression_ratio': 0.9846153846153847, 'no_speech_prob': 0.07707208395004272}], 'language': 'hi'}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}